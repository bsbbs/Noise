bwcols <- c(graytrnsp, redtrnsp)
ord <- c(4,1,3,2,5)
randomeffects$meanval <- randomeffects$mean
randomeffects$effsz <- randomeffects$meanval/randomeffects$sd
IndvESTPs <- c()
for (gi in 1:2)
{
par(mfrow = c(3,2))
group <- gnames[gi]
gmask <- floor(as.numeric(as.character(randomeffects$subNo))/1000) == gi
sublist <- unique(randomeffects$subNo[gmask])
# invidual curves
for (vi in ord){
allvals <- randomeffects$effsz[randomeffects$var == varsp[vi] & randomeffects$time >= 70]
yax <- MyYlim(allvals)
for (si in 1:length(sublist)){
mask <- randomeffects$var == varsp[vi] & randomeffects$subNo == sublist[si]
meanval <- randomeffects$effsz[mask]
if (si == 1) {plot(tbin,rep(0,length(tbin)), type = 'l', lty = 2, ylim = yax$ylims, ylab = ' ', xlab = ' ', main = varsp[vi], frame.plot = FALSE, axes = F, xaxt = "n")
axis(1, at = c(70,80,90,99), tck = -0.03, padj = -.118, cex.axis = 1)
axis(2, at = yax$yticks, tck = -0.03, padj = -.118, cex.axis = 1)
title(ylab = 'Effect size', mgp = c(2.38,0,0), font.lab = 1, cex.lab = 1)
title(xlab = "Time bins", mgp = c(2.38,0,0), font.lab = 1, cex.lab = 1)}
lines(tbin, meanval, col = mycols[vi], lwd = .5)
ESTP <- getESTP(randomeffects[mask,], kthreshold)
IndvESTPs <- rbind(IndvESTPs, data.frame(group, subNo=sublist[si], var = varsp[vi], name = varnames[vi], ESTP))
}
allmean <- aggregate(effsz ~ time, data = randomeffects[randomeffects$var == varsp[vi] & randomeffects$group == group,],FUN = "mean")
lines(tbin, allmean$effsz, col = 1, lwd=1)
}
dev.copy(pdf,file.path(plotdir,sprintf("TimeCourse[Stan]_M7b_IndvEffSize_%s.pdf",group)),height=6, width=5)
dev.off()
}
write.table(IndvESTPs, file = file.path(plotdir,'IndividualESTPs.txt'), col.names = TRUE, quote = FALSE, eol = '\n', na = "NA", row.names = FALSE, sep = '\t')
# Visualize individual ESTPs
par(mfrow = c(3,2))
ord <- c(4,1,3,2,5)
for (vi in ord)
{
ESTP1 <- c()
ESTP2 <- c()
for (gi in 1:2){
group <- gnames[gi]
ESTPs <- IndvESTPs$ESTP[IndvESTPs$group == group & IndvESTPs$var == varsp[vi] & IndvESTPs$ESTP != Inf]
if (gi == 1){ESTP1 <- ESTPs}else{ESTP2 <- ESTPs}
binwd <- 1
hf <- hist(ESTPs, breaks = seq(1,99,binwd), plot = FALSE)
yup <- max(hf$counts)*1.1
if (gi == 2){par(new = TRUE)}
tbins <- 1:99
t1 <- 82
t2 <- 97
barplot(hf$counts[t1:t2], width = 1, space = 0, ylim = c(0,yup), col = bwcols[gi], xlab = ' ', ylab = '', axes = F, main = varnames[vi])
if (gi == 2){
axis(1, at = seq(0,15,5), labels = seq(t1,t2,5), tck = -0.03, padj = -.118, cex.axis = 1.5)
axis(2, at = seq(0,yup,floor(yup)), tck = -0.03, padj = .318, cex.axis = 1.5)
title(ylab = 'Freq.', mgp = c(2.38,0,0), xlab = "Time bins", cex.lab = 1)}
}
test <- t.test(ESTP1, ESTP2, alternative = c("less"), paired = FALSE)
text(2.5, .7*yup, sprintf('t(%2.0f) = %1.2f\n pval = %1.2f',test$parameter, test$statistic, test$p.value))
}
dev.copy(pdf,file.path(plotdir,sprintf("TimeCourse[Stan]_M7b_IndvHist.pdf")),height=5, width=5)
dev.off()
source(file.path(code_dir,'MyYlim.R'))
source(file.path(code_dir,'DefinePars.R'))
vars
par(mfrow = c(3,2))
ord <- c(4,1,3,2,5)
for (vi in ord)
{
ESTP1 <- c()
ESTP2 <- c()
for (gi in 1:2){
group <- gnames[gi]
ESTPs <- IndvESTPs$ESTP[IndvESTPs$group == group & IndvESTPs$var == varsp[vi] & IndvESTPs$ESTP != Inf]
if (gi == 1){ESTP1 <- ESTPs}else{ESTP2 <- ESTPs}
binwd <- 1
hf <- hist(ESTPs, breaks = seq(1,99,binwd), plot = FALSE)
yup <- max(hf$counts)*1.1
if (gi == 2){par(new = TRUE)}
tbins <- 1:99
t1 <- 82
t2 <- 97
barplot(hf$counts[t1:t2], width = 1, space = 0, ylim = c(0,yup), col = bwcols[gi], xlab = ' ', ylab = '', axes = F, main = varnames[vi])
if (gi == 2){
axis(1, at = seq(0,15,5), labels = seq(t1,t2,5), tck = -0.03, padj = -.118, cex.axis = 1.5)
axis(2, at = seq(0,yup,floor(yup)), tck = -0.03, padj = .318, cex.axis = 1.5)
title(ylab = 'Freq.', mgp = c(2.38,0,0), xlab = "Time bins", cex.lab = 1)}
}
test <- t.test(ESTP1, ESTP2, alternative = c("less"), paired = FALSE)
text(2.5, .7*yup, sprintf('t(%2.0f) = %1.2f\n pval = %1.2f',test$parameter, test$statistic, test$p.value))
}
dev.copy(pdf,file.path(plotdir,sprintf("TimeCourse[Stan]_M7b_IndvHist.pdf")),height=5, width=5)
dev.off()
source(file.path(code_dir,'DefinePars.R'))
par(mfrow = c(3,2))
ord <- c(4,1,3,2,5)
for (vi in ord)
{
ESTP1 <- c()
ESTP2 <- c()
for (gi in 1:2){
group <- gnames[gi]
ESTPs <- IndvESTPs$ESTP[IndvESTPs$group == group & IndvESTPs$var == varsp[vi] & IndvESTPs$ESTP != Inf]
if (gi == 1){ESTP1 <- ESTPs}else{ESTP2 <- ESTPs}
binwd <- 1
hf <- hist(ESTPs, breaks = seq(1,99,binwd), plot = FALSE)
yup <- max(hf$counts)*1.1
if (gi == 2){par(new = TRUE)}
tbins <- 1:99
t1 <- 82
t2 <- 97
barplot(hf$counts[t1:t2], width = 1, space = 0, ylim = c(0,yup), col = bwcols[gi], xlab = ' ', ylab = '', axes = F, main = varnames[vi])
if (gi == 2){
axis(1, at = seq(0,15,5), labels = seq(t1,t2,5), tck = -0.03, padj = -.118, cex.axis = 1.5)
axis(2, at = seq(0,yup,floor(yup)), tck = -0.03, padj = .318, cex.axis = 1.5)
title(ylab = 'Freq.', mgp = c(2.38,0,0), xlab = "Time bins", cex.lab = 1)}
}
test <- t.test(ESTP1, ESTP2, alternative = c("less"), paired = FALSE)
text(2.5, .7*yup, sprintf('t(%2.0f) = %1.2f\n pval = %1.2f',test$parameter, test$statistic, test$p.value))
}
dev.copy(pdf,file.path(plotdir,sprintf("TimeCourse[Stan]_M7b_IndvHist.pdf")),height=5, width=5)
dev.off()
library(rstan)
setwd("/Users/bs3667/Noise/UnusedCodeorForFutureAnalyses/modelfit")
library(rstan)
setwd("C:\Users\Bo\Documents\GitHub\Noise\UnusedCodeorForFutureAnalyses\modelfit")
setwd("C:/Users/Bo/Documents/GitHub/Noise/UnusedCodeorForFutureAnalyses/modelfit")
# Simulate the data
set.seed(123)
n_trials <- 1000
utility_apple <- 5.3
utility_orange <- 3.5
beta <- utility_apple - utility_orange
# Simulate trial-level randomness (epsilon)
sigma_true <- 1  # true standard deviation of the trial-level random effect
epsilon_true <- rnorm(n_trials, mean = 0, sd = sigma_true)
# Simulate choices based on the true model
prob_apple <- 1 / (1 + exp(-(beta + epsilon_true)))
choices <- rbinom(n_trials, 1, prob_apple)
df <- data.frame(trial = 1:n_trials, choice = choices)
# Prepare data for Stan
stan_data <- list(
N = nrow(df),
y = df$choice
)
# Compile and fit the Stan model
# stan_model <- stan_model(file = 'choice_model_with_latent.stan')
stan_model <- stan_model(file = 'choice_model.stan')
fit <- sampling(stan_model, data = stan_data, iter = 2000, warmup = 1000, chains = 4, seed = 123)
# Print the results
print(fit)
library(rstan)
setwd("C:/Users/Bo/Documents/GitHub/Noise/UnusedCodeorForFutureAnalyses/modelfit")
# Simulate the data
set.seed(123)
n_trials <- 1000
utility_apple <- 5.3
utility_orange <- 3.5
beta <- utility_apple - utility_orange
# Simulate trial-level randomness (epsilon)
sigma_true <- 1  # true standard deviation of the trial-level random effect
epsilon_true <- rnorm(n_trials, mean = 0, sd = sigma_true)
# Simulate choices based on the true model
prob_apple <- 1 / (1 + exp(-(beta + epsilon_true)))
choices <- rbinom(n_trials, 1, prob_apple)
df <- data.frame(trial = 1:n_trials, choice = choices)
# Prepare data for Stan
stan_data <- list(
N = nrow(df),
y = df$choice
)
# Compile and fit the Stan model
stan_model <- stan_model(file = 'choice_model_with_latent.stan')
# Fit the model
fit <- sampling(stan_model, data = stan_data, iter = 2000, warmup = 1000, chains = 4, seed = 123)
# Print the results
print(fit)
# Check convergence diagnostics
print(fit, pars = c("alpha", "sigma"), probs = c(0.025, 0.5, 0.975))
# Trace plots for key parameters
traceplot(fit, pars = c("alpha", "sigma"))
# Posterior predictive checks
posterior_samples <- extract(fit)
alpha_samples <- posterior_samples$alpha
sigma_samples <- posterior_samples$sigma
epsilon_samples <- posterior_samples$epsilon
# Summarize the results
alpha_hat <- mean(alpha_samples)
sigma_hat <- mean(sigma_samples)
epsilon_hat <- apply(epsilon_samples, 2, mean)
# Print the estimated parameters
print(paste("Estimated alpha (bias): ", alpha_hat))
print(paste("Estimated sigma (trial-level SD): ", sigma_hat))
# Predict choices using the estimated alpha and epsilon
predicted_prob <- 1 / (1 + exp(-(alpha_hat + epsilon_hat)))
predicted_choices <- ifelse(predicted_prob > 0.5, 1, 0)
# Compare with actual choices
comparison <- data.frame(
trial = df$trial,
actual_choice = df$choice,
predicted_choice = predicted_choices,
predicted_prob = predicted_prob
)
# Calculate prediction accuracy
accuracy <- mean(comparison$actual_choice == comparison$predicted_choice)
print(paste("Prediction Accuracy: ", accuracy))
predicted_prob
epsilon_hat
alpha_hat
library(rstan)
setwd("C:/Users/Bo/Documents/GitHub/Noise/UnusedCodeorForFutureAnalyses/modelfit")
# Simulate the data
set.seed(123)
n_trials <- 1000
utility_apple <- 5.3
utility_orange <- 3.5
beta <- utility_apple - utility_orange
# Simulate trial-level randomness (epsilon)
sigma_true <- 1  # true standard deviation of the trial-level random effect
epsilon_true <- rnorm(n_trials, mean = 0, sd = sigma_true)
# Simulate choices based on the true model
prob_apple <- 1 / (1 + exp(-(beta + epsilon_true)))
choices <- rbinom(n_trials, 1, prob_apple)
df <- data.frame(trial = 1:n_trials, choice = choices)
# Prepare data for Stan
stan_data <- list(
N = nrow(df),
y = df$choice
)
# Compile and fit the Stan model
# stan_model <- stan_model(file = 'choice_model_with_latent.stan')
stan_model <- stan_model(file = 'choice_model.stan')
fit <- sampling(stan_model, data = stan_data, iter = 2000, warmup = 1000, chains = 4, seed = 123)
# Print the results
print(fit)
# Check convergence diagnostics
print(fit, pars = c("alpha", "sigma"), probs = c(0.025, 0.5, 0.975))
# Trace plots for key parameters
traceplot(fit, pars = c("alpha", "sigma"))
# Posterior predictive checks
posterior_samples <- extract(fit)
alpha_samples <- posterior_samples$alpha
sigma_samples <- posterior_samples$sigma
epsilon_samples <- posterior_samples$z
# Summarize the results
alpha_hat <- mean(alpha_samples)
sigma_hat <- mean(sigma_samples)
epsilon_hat <- apply(epsilon_samples, 2, mean)
# Print the estimated parameters
print(paste("Estimated alpha (bias): ", alpha_hat))
print(paste("Estimated sigma (trial-level SD): ", sigma_hat))
# Predict choices using the estimated alpha and epsilon
predicted_prob <- 1 / (1 + exp(-(alpha_hat + sigma_hat*epsilon_hat)))
predicted_choices <- ifelse(predicted_prob > 0.5, 1, 0)
epsilon_hat
# Predict choices using the estimated alpha and epsilon
predicted_prob <- 1 / (1 + exp(-(alpha_hat + sigma_hat*epsilon_hat)))
predicted_choices <- ifelse(predicted_prob > 0.5, 1, 0)
# Compare with actual choices
comparison <- data.frame(
trial = df$trial,
actual_choice = df$choice,
predicted_choice = predicted_choices,
predicted_prob = predicted_prob
)
# Calculate prediction accuracy
accuracy <- mean(comparison$actual_choice == comparison$predicted_choice)
print(paste("Prediction Accuracy: ", accuracy))
# Extract log-likelihood
log_lik <- extract(fit)$log_lik
# Summarize the log-likelihood
log_lik_mean <- apply(log_lik, 2, mean)
log_lik_sum <- sum(log_lik_mean)
print(paste("Sum of log-likelihood: ", log_lik_sum))
log_lik_mean
comparison$actual_choice
predicted_prob
log_lik\
log_lik
epsilon_samples
epsilon_hat
mean(epsilon_hat)
sd(epsilon_hat)
sigma_hat
alpha_hat
library(rstan)
setwd("C:/Users/Bo/Documents/GitHub/Noise/UnusedCodeorForFutureAnalyses/modelfit")
# Simulate the data
set.seed(123)
n_trials <- 1000
utility_apple <- 5.3
utility_orange <- 3.5
beta <- utility_apple - utility_orange
# Simulate trial-level randomness (epsilon)
sigma_true <- 1  # true standard deviation of the trial-level random effect
epsilon_true <- rnorm(n_trials, mean = 0, sd = sigma_true)
# Simulate choices based on the true model
prob_apple <- 1 / (1 + exp(-(beta + epsilon_true)))
choices <- rbinom(n_trials, 1, prob_apple)
df <- data.frame(trial = 1:n_trials, choice = choices)
# Prepare data for Stan
stan_data <- list(
N = nrow(df),
y = df$choice
)
# Compile and fit the Stan model
stan_model <- stan_model(file = 'choice_model_with_latent.stan')
# stan_model <- stan_model(file = 'choice_model.stan')
fit <- sampling(stan_model, data = stan_data, iter = 2000, warmup = 1000, chains = 4, seed = 123)
# Print the results
print(fit)
# Trace plots for key parameters
traceplot(fit, pars = c("alpha", "sigma"))
# Extract log-likelihood
log_lik <- extract(fit)$log_lik
log_lik
# Summarize the log-likelihood
log_lik_mean <- apply(log_lik, 2, mean)
log_lik_sum <- sum(log_lik_mean)
print(paste("Sum of log-likelihood: ", log_lik_sum))
log_lik_mean
mean(epsilon_hat)
sd(epsilon_hat)
posterior_samples <- extract(fit)
alpha_samples <- posterior_samples$alpha
sigma_samples <- posterior_samples$sigma
epsilon_samples <- posterior_samples$epsilon
# Summarize the results
alpha_hat <- mean(alpha_samples)
sigma_hat <- mean(sigma_samples)
epsilon_hat <- apply(epsilon_samples, 2, mean)
alpha_hat
sigma_hat
epsilon_hat
sigma_hat
sd(epsilon_hat)
sd(epsilon_hat)^.5
mcmc_dens(fit, pars = c("alpha", "sigma"))
library(rstan)
mcmc_dens(fit, pars = c("alpha", "sigma"))
install.packages('bayesplot')
require(bayesplot)
mcmc_dens(fit, pars = c("alpha", "sigma"))
mcmc_dens(fit, pars = c("alpha", "sigma", 'epsilon'))
# Print the results
print(fit)
mcmc_dens(fit, pars = c("epsilon[1]", "epsilon[2]", "epsilon[3]"))
fit <- sampling(stan_model, data = stan_data, iter = 4000, warmup = 2000, chains = 4, seed = 123)
library(rstan)
setwd("C:/Users/Bo/Documents/GitHub/Noise/UnusedCodeorForFutureAnalyses/modelfit")
# Simulate the data
set.seed(123)
n_trials <- 1000
utility_apple <- 5.3
utility_orange <- 3.5
beta <- utility_apple - utility_orange
# Simulate trial-level randomness (epsilon)
sigma_true <- 1  # true standard deviation of the trial-level random effect
epsilon_true <- rnorm(n_trials, mean = 0, sd = sigma_true)
# Simulate choices based on the true model
prob_apple <- 1 / (1 + exp(-(beta + epsilon_true)))
choices <- rbinom(n_trials, 1, prob_apple)
df <- data.frame(trial = 1:n_trials, choice = choices)
# Prepare data for Stan
stan_data <- list(
N = nrow(df),
y = df$choice
)
# Compile and fit the Stan model
stan_model <- stan_model(file = 'choice_model_with_latent.stan')
# stan_model <- stan_model(file = 'choice_model.stan')
# Fit the model
fit <- sampling(stan_model, data = stan_data, iter = 4000, warmup = 2000, chains = 4, seed = 123)
# Print the results
print(fit)
# Check convergence diagnostics
print(fit, pars = c("alpha", "sigma"), probs = c(0.025, 0.5, 0.975))
# Trace plots for key parameters
traceplot(fit, pars = c("alpha", "sigma"))
require(bayesplot)
mcmc_dens(fit, pars = c("alpha", "sigma"))
mcmc_dens(fit, pars = c("epsilon[1]", "epsilon[2]", "epsilon[3]"))
# Posterior predictive checks
posterior_samples <- extract(fit)
alpha_samples <- posterior_samples$alpha
sigma_samples <- posterior_samples$sigma
epsilon_samples <- posterior_samples$epsilon
library(rstan)
setwd("C:/Users/Bo/Documents/GitHub/Noise/UnusedCodeorForFutureAnalyses/modelfit")
# Simulate the data
set.seed(123)
n_trials <- 1000
utility_apple <- 5.3
utility_orange <- 3.5
beta <- utility_apple - utility_orange
# Simulate trial-level randomness (epsilon)
sigma_true <- 1  # true standard deviation of the trial-level random effect
epsilon_true <- rnorm(n_trials, mean = 0, sd = sigma_true)
# Simulate choices based on the true model
prob_apple <- 1 / (1 + exp(-(beta + epsilon_true)))
choices <- rbinom(n_trials, 1, prob_apple)
df <- data.frame(trial = 1:n_trials, choice = choices)
# Prepare data for Stan
stan_data <- list(
N = nrow(df),
y = df$choice
)
# Compile and fit the Stan model
stan_model <- stan_model(file = 'choice_model_with_latent.stan')
# stan_model <- stan_model(file = 'choice_model.stan')
# Fit the model
fit <- sampling(stan_model, data = stan_data, iter = 4000, warmup = 2000, chains = 4, seed = 123)
# Print the results
print(fit)
# Check convergence diagnostics
print(fit, pars = c("sigma"), probs = c(0.025, 0.5, 0.975))
# Trace plots for key parameters
traceplot(fit, pars = c(sigma"))
# Trace plots for key parameters
traceplot(fit, pars = c("sigma"))
mcmc_dens(fit, pars = c("sigma"))
mcmc_dens(fit, pars = c("epsilon[1]", "epsilon[2]", "epsilon[3]"))
mcmc_dens(fit, pars = c("sigma"))
cauchy
library(rstan)
setwd("C:/Users/Bo/Documents/GitHub/Noise/UnusedCodeorForFutureAnalyses/modelfit")
# Simulate the data
set.seed(123)
n_trials <- 1000
utility_apple <- 5.3
utility_orange <- 3.5
beta <- utility_apple - utility_orange
# Simulate trial-level randomness (epsilon)
sigma_true <- 1  # true standard deviation of the trial-level random effect
epsilon_true <- rnorm(n_trials, mean = 0, sd = sigma_true)
# Simulate choices based on the true model
prob_apple <- 1 / (1 + exp(-(beta + epsilon_true)))
choices <- rbinom(n_trials, 1, prob_apple)
df <- data.frame(trial = 1:n_trials, choice = choices)
# Prepare data for Stan
stan_data <- list(
N = nrow(df),
y = df$choice
)
# Compile and fit the Stan model
# stan_model <- stan_model(file = 'choice_model_with_latent.stan')
stan_model <- stan_model(file = 'choice_model.stan')
# Fit the model
fit <- sampling(stan_model, data = stan_data, iter = 4000, warmup = 2000, chains = 4, seed = 123)
# Print the results
print(fit)
# Check convergence diagnostics
print(fit, pars = c("sigma"), probs = c(0.025, 0.5, 0.975))
# Trace plots for key parameters
traceplot(fit, pars = c("sigma"))
# Print the results
print(fit)
mcmc_dens(fit, pars = c("z[1]", "z[2]", "z[3]"))
mcmc_dens(fit, pars = c("sigma"))
# Extract log-likelihood
log_lik <- extract(fit)$log_lik
# Summarize the log-likelihood
log_lik_mean <- apply(log_lik, 2, mean)
log_lik_mean
traceplot(fit, pars = c("z[1]"))
# Posterior predictive checks
posterior_samples <- extract(fit)
sigma_samples <- posterior_samples$sigma
z <- posterior_samples$z
sigma_samples <- posterior_samples$sigma
z_samples <- posterior_samples$z
# Summarize the results
sigma_hat <- mean(sigma_samples)
z_hat <- apply(z_samples, 2, mean)
sigma_hat
# Print the estimated parameters
print(paste("Estimated sigma (trial-level SD): ", sigma_hat))
# Predict choices using the estimated alpha and epsilon
predicted_prob <- 1 / (1 + exp(-(1 + sigma_hat*z_hat)))
plot(predicted_prob)
z_hat
hist(z_hat)
hist(sigma_hat*z_hat)
order(predicted_choices)
sort(predicted_choices)
predicted_choices <- ifelse(predicted_prob > 0.5, 1, 0)
sort(predicted_choices)
sort(predicted_prob)
library(rstan)
setwd("C:/Users/Bo/Documents/GitHub/Noise/UnusedCodeorForFutureAnalyses/modelfit")
# Simulate the data
set.seed(123)
n_trials <- 1000
utility_apple <- 5.3
utility_orange <- 3.5
beta <- utility_apple - utility_orange
# Simulate trial-level randomness (epsilon)
sigma_true <- 1  # true standard deviation of the trial-level random effect
epsilon_true <- rnorm(n_trials, mean = 0, sd = sigma_true)
# Simulate choices based on the true model
prob_apple <- 1 / (1 + exp(-(beta + epsilon_true)))
choices <- rbinom(n_trials, 1, prob_apple)
df <- data.frame(trial = 1:n_trials, choice = choices)
# Prepare data for Stan
stan_data <- list(
N = nrow(df),
y = df$choice
)
# Compile and fit the Stan model
# stan_model <- stan_model(file = 'choice_model_with_latent.stan')
stan_model <- stan_model(file = 'choice_model.stan')
